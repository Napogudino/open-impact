{
    "docs": [
        {
            "location": "/", 
            "text": "Terra 2018 \nPlanet \n Earth Engine\n\n\nMessage from Terra\n\n\nCICESE is pleased to invite you to our Pointcloud And Remote Sensing Workshop Aimed at undergraduates, postgraduates and researchers in Earth / Ocean sciences, Computing, private companies (environmental consultancy, geomatics, topographic, geodesic services), NGOs (conservation, environment) From august 14 to 16 2018, at CICESE on Ensenada, B.C.\n\n\n\n\nThe Planet Story\n\n\nWith \nmission one completed\n Planet has the capability of mapping the entire planet every single day. We are trying to ask the harder question, the ones that are yet to be asked and answered. For now this notion of \nbuilding a queryable earth as mission two\n, comes from our passion to look and to search for things.\n\n\n\n\nGoogle Earth Engine \nBrowser Based Remote Sensing\n\n\nI like to tell people that Google Earth Engine does browser based remote sensing , because all you need is an active internet connection and a browser to run this. To bring us to a fair playing field when it comes to analyzing and repeating data analysis.", 
            "title": "Terra 2018"
        }, 
        {
            "location": "/#terra-2018-planet-earth-engine", 
            "text": "", 
            "title": "Terra 2018 Planet &amp; Earth Engine"
        }, 
        {
            "location": "/#message-from-terra", 
            "text": "CICESE is pleased to invite you to our Pointcloud And Remote Sensing Workshop Aimed at undergraduates, postgraduates and researchers in Earth / Ocean sciences, Computing, private companies (environmental consultancy, geomatics, topographic, geodesic services), NGOs (conservation, environment) From august 14 to 16 2018, at CICESE on Ensenada, B.C.", 
            "title": "Message from Terra"
        }, 
        {
            "location": "/#the-planet-story", 
            "text": "With  mission one completed  Planet has the capability of mapping the entire planet every single day. We are trying to ask the harder question, the ones that are yet to be asked and answered. For now this notion of  building a queryable earth as mission two , comes from our passion to look and to search for things.", 
            "title": "The Planet Story"
        }, 
        {
            "location": "/#google-earth-engine-browser-based-remote-sensing", 
            "text": "I like to tell people that Google Earth Engine does browser based remote sensing , because all you need is an active internet connection and a browser to run this. To bring us to a fair playing field when it comes to analyzing and repeating data analysis.", 
            "title": "Google Earth Engine Browser Based Remote Sensing"
        }, 
        {
            "location": "/planetee/", 
            "text": "Introduction\n\n\nAs Planet achieved \nmission one\n last year it started to map the entire planet every single day. With this came the need to store tremendous amount of data, being able to serve it using our faboulous \nPlanet Explorer\n and for you be able to dowload it after you created an account. While getting imagery became critically important , the delivery method lead to questions about platforms for analysis. Mission one further meant that you would be able to analyze time series datasets over weekly and bi weekly periods and understand questions that require dynamic analysis such as vegetation patters, climate variability and changes in hydrological cycles. It generated the single largest trove of high frequency dataset in existence with an unprecedented cadence or repeat over areas.\n\n\n\n\nPlanet by the numbers from \nWill Marshall\u2019s post\n \u00a9 Planet Labs\n\n\nWith the need to handle such global-scale and often massive data sets, Google was already building and hosting a platform called \nGoogle Earth Engine(GEE)\n designed to analyze geo-spatial data. Google Earth Engine is a cloud based analysis platform that allows for an indexable and queriable raster and vector environment while including and expanding on raster capabilities. It allows for users to perform large scale analysis on large scale datasets such as Planet's very own. You can read more about the Google Earth Engine platform \nhere\n\n\n\n\nThese set of tutorials will introduce you to methods in getting imagery onto the Google Earth Engine platform, and how do you quickly visualize and analyze the datasets with the GEE platform. With the multitude of tools and possibilities of building your own analysis tools. The first of it's kind tools will include basic methods such as 4 band operations and can include complex operations in machine learning as the platform evolves.\n\n\nFor more information and developer guide on Google Earth Engine you can visit their \ndeveloper console\n.", 
            "title": "Planet & Google Earth Engine"
        }, 
        {
            "location": "/planetee/#introduction", 
            "text": "As Planet achieved  mission one  last year it started to map the entire planet every single day. With this came the need to store tremendous amount of data, being able to serve it using our faboulous  Planet Explorer  and for you be able to dowload it after you created an account. While getting imagery became critically important , the delivery method lead to questions about platforms for analysis. Mission one further meant that you would be able to analyze time series datasets over weekly and bi weekly periods and understand questions that require dynamic analysis such as vegetation patters, climate variability and changes in hydrological cycles. It generated the single largest trove of high frequency dataset in existence with an unprecedented cadence or repeat over areas.   Planet by the numbers from  Will Marshall\u2019s post  \u00a9 Planet Labs  With the need to handle such global-scale and often massive data sets, Google was already building and hosting a platform called  Google Earth Engine(GEE)  designed to analyze geo-spatial data. Google Earth Engine is a cloud based analysis platform that allows for an indexable and queriable raster and vector environment while including and expanding on raster capabilities. It allows for users to perform large scale analysis on large scale datasets such as Planet's very own. You can read more about the Google Earth Engine platform  here   These set of tutorials will introduce you to methods in getting imagery onto the Google Earth Engine platform, and how do you quickly visualize and analyze the datasets with the GEE platform. With the multitude of tools and possibilities of building your own analysis tools. The first of it's kind tools will include basic methods such as 4 band operations and can include complex operations in machine learning as the platform evolves.  For more information and developer guide on Google Earth Engine you can visit their  developer console .", 
            "title": "Introduction"
        }, 
        {
            "location": "/planet-asset/", 
            "text": "Understand Planet Items-Assets \n API\n\n\nYou can read the most updated white paper on planet products, items, assets and specifications \nhere\n. While you look at these spec sheets try to understand how you would want to use the data, the purpose and scope of the question you want to answer, the size of downloads and the overall product or derivate in mind. To think of Planet products you have to understand two terms as thought they live in a hierarchy\n\n\n\n\nPlanet Imagery Product Offerings\n\n\nItems and Assets\n\n\n\n\n\n\nItem type almost refers exclusively to a family of satellite or sensor types so PlanetScope, RapidEye, Skysat, Landsat and so on are all item types. These are model definitions based on the type of sensor you are utilizing for performing any type of analysis.\n\n\n\n\n\n\nAsset types are types of item derivatives or data types that you are actually utilizing for example analytic, analytic_sr, analytic_xml, visual and so on. These allow you to choose the type of actual data that you are able to download including the type and level of preprocesing that has been applied to it.\n\n\n\n\n\n\nFor further reference on item asset relationships you can \nvisit the docs\n\n\nNow the assumption here is that after you have created your account you have downloaded data either from \nPlanet Explorer\n or you have been curious and looked into the data API and used the wonderful \npython client\n from planet. Incase you have not and you have python on your system, invoke the power of pip and type\n\n\npip install planet\n\n\nThere is so much more to be done using planet data using some amazing API(s) including\n\n\n\n\n\n\nWhat if you wanted to download hundreds and thousands of scenes for your analysis, the \nData API\n will allow you to understand the backend.\n\n\n\n\n\n\nIf you want your images to be automatically clipped to your area of interest, you can use the \nClips API", 
            "title": "Planet Imagery"
        }, 
        {
            "location": "/planet-asset/#understand-planet-items-assets-api", 
            "text": "You can read the most updated white paper on planet products, items, assets and specifications  here . While you look at these spec sheets try to understand how you would want to use the data, the purpose and scope of the question you want to answer, the size of downloads and the overall product or derivate in mind. To think of Planet products you have to understand two terms as thought they live in a hierarchy   Planet Imagery Product Offerings", 
            "title": "Understand Planet Items-Assets &amp; API"
        }, 
        {
            "location": "/planet-asset/#items-and-assets", 
            "text": "Item type almost refers exclusively to a family of satellite or sensor types so PlanetScope, RapidEye, Skysat, Landsat and so on are all item types. These are model definitions based on the type of sensor you are utilizing for performing any type of analysis.    Asset types are types of item derivatives or data types that you are actually utilizing for example analytic, analytic_sr, analytic_xml, visual and so on. These allow you to choose the type of actual data that you are able to download including the type and level of preprocesing that has been applied to it.    For further reference on item asset relationships you can  visit the docs  Now the assumption here is that after you have created your account you have downloaded data either from  Planet Explorer  or you have been curious and looked into the data API and used the wonderful  python client  from planet. Incase you have not and you have python on your system, invoke the power of pip and type  pip install planet  There is so much more to be done using planet data using some amazing API(s) including    What if you wanted to download hundreds and thousands of scenes for your analysis, the  Data API  will allow you to understand the backend.    If you want your images to be automatically clipped to your area of interest, you can use the  Clips API", 
            "title": "Items and Assets"
        }, 
        {
            "location": "/projects/images/", 
            "text": "Images in Earth Engine\n\n\nIn the GEE environment images are stored in Cloud Optimized Geospatial tiles instead of a single image which allows for running an analysis this scale. This means that though the input imagery comes in know formats such as geotiff , MrSid and img these datasets post ingestion into GEE are converted into tiles that are used for at scale analysis. All images that are ingested into either GEE(s) Raster Catalog or your own personal folder and stored in folder or collections of images as you would expect to see when doing deep time stack analysis.\n\n\n\n\nThese images have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them\n\n\n//Add an image\n\n\nvar\n \nimage\n=\nee\n.\nImage\n(\nLANDSAT/LT05/C01/T1_SR/LT05_025039_19841105\n)\n\n\nprint\n(\nSingle Image\n,\nimage\n)\n\n\n\n//Center the Map to the image and add the image\n\n\nMap\n.\ncenterObject\n(\ngeometry\n,\n10\n)\n\n\nMap\n.\naddLayer\n(\nimage\n,\nvis\n,\nImage\n)\n\n\n\n//Clip an image\n\n\nvar\n \nclipped\n=\nimage\n.\nclip\n(\ngeometry\n)\n\n\nMap\n.\naddLayer\n(\nclipped\n,\nvis\n,\nClipped Image\n)", 
            "title": "Images"
        }, 
        {
            "location": "/projects/images/#images-in-earth-engine", 
            "text": "In the GEE environment images are stored in Cloud Optimized Geospatial tiles instead of a single image which allows for running an analysis this scale. This means that though the input imagery comes in know formats such as geotiff , MrSid and img these datasets post ingestion into GEE are converted into tiles that are used for at scale analysis. All images that are ingested into either GEE(s) Raster Catalog or your own personal folder and stored in folder or collections of images as you would expect to see when doing deep time stack analysis.   These images have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them  //Add an image  var   image = ee . Image ( LANDSAT/LT05/C01/T1_SR/LT05_025039_19841105 )  print ( Single Image , image )  //Center the Map to the image and add the image  Map . centerObject ( geometry , 10 )  Map . addLayer ( image , vis , Image )  //Clip an image  var   clipped = image . clip ( geometry )  Map . addLayer ( clipped , vis , Clipped Image )", 
            "title": "Images in Earth Engine"
        }, 
        {
            "location": "/projects/imagecollection/", 
            "text": "Image Collections in Earth Engine\n\n\nWhile single images are great to do quick analytics, the true power of the Earth Engine environment comes with the possibility of looking at really large and heavy image collections and to be able to push analysis towards the data, rather than the need for the data to travel at all. In the GEE environment image collections have their own characteristic setup and are composted with single images that we discussed earlier. They can often have the same or different band structure but generally share a similar metadata structure for filtering and querying.\n\n\nLarge scale image collections such as Landsat and Sentinel image collections are ingested on the fly and are actively maintained till there imagery and processing pipelines feeds are maintained byt he agencies supplying the imagery. Images as well as image collections can be moved into GEE environment to allow you to use both your data and the GEE catalog data within the same platform.\n\n\nFor those who are concerned with access to datasets, this means that though Earth Engine allows an easier way to share datasets across users, private folder, collections and imagery are private and are not here the section from their \nTerms and Conditions page\n\n\nIntellectual Property Rights. Except as expressly set forth in this Agreement,\nthis Agreement does not grant either party any rights, implied or otherwise,\nto the other\u2019s content or any of the other\u2019s intellectual property.\nAs between the parties, Customer owns all Intellectual Property Rights\nin Customer Data, Customer Code, and Application(s), and Google owns\nall Intellectual Property Rights in the Services and Software.\n\n\nThese image collection as well as individual imaegs again have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them\n\n\n//Add an image collection\n\n\nvar\n \ncollection\n=\nee\n.\nImageCollection\n(\nLANDSAT/LT05/C01/T1_SR\n)\n\n\n\n//Filtering an Image Collection\n\n\nvar\n \nfiltered\n=\ncollection\n.\nfilterMetadata\n(\nWRS_PATH\n,\nequals\n,\n25\n)\n\n\n.\nfilterMetadata\n(\nWRS_ROW\n,\nequals\n,\n39\n).\nfilterMetadata\n(\nCLOUD_COVER\n,\nless_than\n,\n5\n)\n\n\n\n//print filtered collection properties\n\n\nprint\n(\nFiltered Collection\n,\nfiltered\n)\n\n\n\n\n\nTo have a look at all of the raster catalog you can find them \nlisted here", 
            "title": "Image Collection"
        }, 
        {
            "location": "/projects/imagecollection/#image-collections-in-earth-engine", 
            "text": "While single images are great to do quick analytics, the true power of the Earth Engine environment comes with the possibility of looking at really large and heavy image collections and to be able to push analysis towards the data, rather than the need for the data to travel at all. In the GEE environment image collections have their own characteristic setup and are composted with single images that we discussed earlier. They can often have the same or different band structure but generally share a similar metadata structure for filtering and querying.  Large scale image collections such as Landsat and Sentinel image collections are ingested on the fly and are actively maintained till there imagery and processing pipelines feeds are maintained byt he agencies supplying the imagery. Images as well as image collections can be moved into GEE environment to allow you to use both your data and the GEE catalog data within the same platform.  For those who are concerned with access to datasets, this means that though Earth Engine allows an easier way to share datasets across users, private folder, collections and imagery are private and are not here the section from their  Terms and Conditions page  Intellectual Property Rights. Except as expressly set forth in this Agreement,\nthis Agreement does not grant either party any rights, implied or otherwise,\nto the other\u2019s content or any of the other\u2019s intellectual property.\nAs between the parties, Customer owns all Intellectual Property Rights\nin Customer Data, Customer Code, and Application(s), and Google owns\nall Intellectual Property Rights in the Services and Software.  These image collection as well as individual imaegs again have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them  //Add an image collection  var   collection = ee . ImageCollection ( LANDSAT/LT05/C01/T1_SR )  //Filtering an Image Collection  var   filtered = collection . filterMetadata ( WRS_PATH , equals , 25 )  . filterMetadata ( WRS_ROW , equals , 39 ). filterMetadata ( CLOUD_COVER , less_than , 5 )  //print filtered collection properties  print ( Filtered Collection , filtered )   To have a look at all of the raster catalog you can find them  listed here", 
            "title": "Image Collections in Earth Engine"
        }, 
        {
            "location": "/projects/rpl/", 
            "text": "Registering for a Planet account\n\n\nWhat you need first to get started in simply to register for a Planet account. These account will almost immediately gain access to the Open California Dataset which is maintained regulary and is perhaps one of the largest open imagery dataset at this spatial and temporal resolution. You can find more information about the \nOpen California project here\n. These datasets and full-resolution imagery for the entire state of California are covered under a CC BY-SA 4.0 license via Planet's Open California initiative.\n\n\nIf you are a university researchers, academics, and/or  scientists, your free account allows you to download 10,000 square kilometers of data for non commercial use, every month, anywhere in the world. You can apply for \nEducation and Research account here\n\n\nSign up for a Planet Account\n\n\nPlanet Explorer\n is a powerful tool for exploring Planet's catalog of daily imagery and worldwide mosaics\ndirectly in your browser. It's also your gateway to creating a Planet Account,and gaining access to Planet's APIs.To sign up, visit \nplanet.com/explorer\n and click \nGet Started\n:\n\n\n\n\nGet started with Planet Explorer\nFrom there, click \nSign Up\n in the top right of your screen, and enter your email address to receive an invitation:\n\n\n\n\nSign up with Planet Explorer\n\n\nCheck your email \n follow the directions to complete the registration process.\n\n\nFind your API Key\n\n\nTo use Planet's APIs, you'll need an API key. API keys are available to all registered users with active Planet accounts.Once you're signed up, log in to\n\nplanet.com/account\n to get your API key. Find the \nAPI key\n field under your account information, as seen here:\n\n\n\n\nAccount information (not a real API key)\n\n\nRegistering for a Google Earth Engine Account\n\n\nIf you don\u2019t have a developer account \nsign up for one here\n and make sure you follow the \ninstructions\n to install the python CLI.\n\n\n\n\nThe API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page.\n\n\nGetting Help with Planet and Google Earth Engine\n\n\nBoth Planet and Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s)\n\n\nYou can find \nPlanet Developer Site here\n\n\nand offcourse the \nEarth Engine Developers Page", 
            "title": "Setting up your Accounts"
        }, 
        {
            "location": "/projects/rpl/#registering-for-a-planet-account", 
            "text": "What you need first to get started in simply to register for a Planet account. These account will almost immediately gain access to the Open California Dataset which is maintained regulary and is perhaps one of the largest open imagery dataset at this spatial and temporal resolution. You can find more information about the  Open California project here . These datasets and full-resolution imagery for the entire state of California are covered under a CC BY-SA 4.0 license via Planet's Open California initiative.  If you are a university researchers, academics, and/or  scientists, your free account allows you to download 10,000 square kilometers of data for non commercial use, every month, anywhere in the world. You can apply for  Education and Research account here", 
            "title": "Registering for a Planet account"
        }, 
        {
            "location": "/projects/rpl/#sign-up-for-a-planet-account", 
            "text": "Planet Explorer  is a powerful tool for exploring Planet's catalog of daily imagery and worldwide mosaics\ndirectly in your browser. It's also your gateway to creating a Planet Account,and gaining access to Planet's APIs.To sign up, visit  planet.com/explorer  and click  Get Started :   Get started with Planet Explorer\nFrom there, click  Sign Up  in the top right of your screen, and enter your email address to receive an invitation:   Sign up with Planet Explorer  Check your email   follow the directions to complete the registration process.", 
            "title": "Sign up for a Planet Account"
        }, 
        {
            "location": "/projects/rpl/#find-your-api-key", 
            "text": "To use Planet's APIs, you'll need an API key. API keys are available to all registered users with active Planet accounts.Once you're signed up, log in to planet.com/account  to get your API key. Find the  API key  field under your account information, as seen here:   Account information (not a real API key)", 
            "title": "Find your API Key"
        }, 
        {
            "location": "/projects/rpl/#registering-for-a-google-earth-engine-account", 
            "text": "If you don\u2019t have a developer account  sign up for one here  and make sure you follow the  instructions  to install the python CLI.   The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page.", 
            "title": "Registering for a Google Earth Engine Account"
        }, 
        {
            "location": "/projects/rpl/#getting-help-with-planet-and-google-earth-engine", 
            "text": "Both Planet and Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s)  You can find  Planet Developer Site here  and offcourse the  Earth Engine Developers Page", 
            "title": "Getting Help with Planet and Google Earth Engine"
        }, 
        {
            "location": "/projects/housekeeping/", 
            "text": "Housekeeping and Setup\n\n\nFor most users data usage often boils down to the software you use to analyze and manipulate images and how you are going to work with them. So here are going to do some housekeeping and setup depending on which tools and setup you are most comfortable with\n\n\n1) Python Setup and libraries\n\n\nDepending on what type of usage you are interested and the libraries you want to use you can find Python installations \nhere\n. And here are some of the libraries you can use with that including but not limited to GDAL, \nScipy\n,\nNumpy\n, \nMatplotlib\n, \nPandas\n, \nFiona\n and \nShapely\n. This list is not exhaustive and include anything else you might need like \nscikit\n or learn \nopencv\n All of \nPypi\n is your oyster\n\n\nfor most systems you can copy and paste this if you have pip on your native command line or terminal\n\n\npip install numpy scipy fiona shapely matplotlib pandas\n\n\nFor Ubuntu and Debian users this might work better and I borrowed it from the installation page at \nScipy\n\n\nsudo apt-get install python-numpy python-scipy python-matplotlib python-pandas\n\n\nNote that GDAL involves a few additional steps for installation on windows machines \nYou can read more about it here\n\n\nTwo other tools or setups which might be handy include\n\n\nvirtualenv\n\n\nvirtualenv allows the user to create and manage seperate package installations fo multiple projects. Think of this as your new project can have its own set of user libraries seperated from the native python libraries. It allows you to create isolated environments for projects and install packages into that virtual isolated environments.\n\n\nA simple installation would be\n\npip install virtualenv\n\n\nYou can get more details about installation on different operation systems and activation of this environment by \nreading their docs\n.\n\n\njupyter notebook\n\n\nThe jupyter hub defined jupyter notebook as\n\n\nThe Jupyter Notebook is an open-source web application that allows you to create\nand share documents that contain live code, equations, visualizations and narrative text.\n\n\n\n\nA lot of the tool chains and processes have been already built into jupyter notebooks for you to use,\n\n\n2) Planet and Google Earth Engine(GEE) Command Line Interface(CLI) Setup\n\n\nYou planet account comes with a brand new CLI and it allows you to perfrom basic functions such as search for ID[s] and for images in a specific location, export all image footprint in your area of interest and so on. Installation is pretty simple\n\n\npip install planet\n\n\nYou installation steps from earlier means you have managed to not only create the Google Earth Engine account but also installed its client. Incase you have missed it go to their main reference page for installation of their python client. Since you can consume Earth Engine using both Javascript(in browser) and Python(locally).\n\n\n3) Location to GEE datasets\n\n\nFrom \nGuillermo E. Ponce-Campos's earlier presentation\n, you saw the application of some datasets within Google Earth Engine. If the data is maintained as open access then you can add any of the datasets by simply adding the following lines first\n\n\nvar\n \nneon_srer_hs\n \n=\n \nee\n.\nImageCollection\n(\nusers/gponce/usda_ars/image_collections/neon_srer_2017_hs\n)\n\n\nvar\n \nrgb10cm\n \n=\n \nee\n.\nImageCollection\n(\nusers/gponce/usda_ars/image_collections/neon_srer_2017_rgb\n)\n\n\nvar\n \nltar_sites\n \n=\n \nee\n.\nFeatureCollection\n(\nusers/gponce/usda_ars/shapefiles/LTAR/ltar_boundaries\n)\n\n\n\n//get size of collection\n\n\nprint\n(\nneon_sres_hs\n.\nsize\n())\n\n\n\n\n\nfor those using python API you can still access a collection\n\n\nimport\n \nee\n\n\nee\n.\nInitialize\n()\n\n\nneon_sres_hs\n=\nee\n.\nImageCollection\n(\nusers/gponce/usda_ars/image_collections/neon_srer_2017_hs\n)\n\n\n\n##you can even check how many images does the collection have\n\n\nprint\n(\nneon_sres_hs\n.\nsize\n()\n.\ngetInfo\n())\n\n\n\n\n\n4) Adding additional Images\n\n\nFor a minute there imagine you want to work with more data apart from the few areas we talked about, the Education and Research account gives you 10,000 square kilometer and you can then upload it into GEE.\n\n\nFor the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually.\n\n\nThe image name is automatically filled in with the filename that you select when uploading.\n\n\n\n\nNote you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help such as using the Google Earth Engine CLI.\n\n\nFor now you can use the tool I made to \nbatch upload collections along with their metadata into Google Earth Engine\n. You can install this by simply typing\n\n\npip install ppipe\n\n\nYou can read about the tool, it's setup and it's operation at \nthis Planet Story\n\n\nIncase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be \nfound here\n\n\n5) Additional Tools and Toolboxes for Local Analysis\n\n\nIf you need to handle the data locally using Matlab, QGIS or ArcMap make sure you have these softwares installed. The images can then be downloaded and analyzed using multiple methods and toolsets. A lot of these softwares have additional capabilities to help you further use Planet data. You can find a better reference of external integration here\n\n\n\n\nENVI Integration\n\n\nESRI Integration\n\n\nCesium Integration\n\n\nBoundless\n\n\nPCI Geomatics", 
            "title": "Basic Housekeeping and Setup"
        }, 
        {
            "location": "/projects/housekeeping/#housekeeping-and-setup", 
            "text": "For most users data usage often boils down to the software you use to analyze and manipulate images and how you are going to work with them. So here are going to do some housekeeping and setup depending on which tools and setup you are most comfortable with", 
            "title": "Housekeeping and Setup"
        }, 
        {
            "location": "/projects/housekeeping/#1-python-setup-and-libraries", 
            "text": "Depending on what type of usage you are interested and the libraries you want to use you can find Python installations  here . And here are some of the libraries you can use with that including but not limited to GDAL,  Scipy , Numpy ,  Matplotlib ,  Pandas ,  Fiona  and  Shapely . This list is not exhaustive and include anything else you might need like  scikit  or learn  opencv  All of  Pypi  is your oyster  for most systems you can copy and paste this if you have pip on your native command line or terminal  pip install numpy scipy fiona shapely matplotlib pandas  For Ubuntu and Debian users this might work better and I borrowed it from the installation page at  Scipy  sudo apt-get install python-numpy python-scipy python-matplotlib python-pandas  Note that GDAL involves a few additional steps for installation on windows machines  You can read more about it here  Two other tools or setups which might be handy include", 
            "title": "1) Python Setup and libraries"
        }, 
        {
            "location": "/projects/housekeeping/#virtualenv", 
            "text": "virtualenv allows the user to create and manage seperate package installations fo multiple projects. Think of this as your new project can have its own set of user libraries seperated from the native python libraries. It allows you to create isolated environments for projects and install packages into that virtual isolated environments.  A simple installation would be pip install virtualenv  You can get more details about installation on different operation systems and activation of this environment by  reading their docs .", 
            "title": "virtualenv"
        }, 
        {
            "location": "/projects/housekeeping/#jupyter-notebook", 
            "text": "The jupyter hub defined jupyter notebook as  The Jupyter Notebook is an open-source web application that allows you to create\nand share documents that contain live code, equations, visualizations and narrative text.  A lot of the tool chains and processes have been already built into jupyter notebooks for you to use,", 
            "title": "jupyter notebook"
        }, 
        {
            "location": "/projects/housekeeping/#2-planet-and-google-earth-enginegee-command-line-interfacecli-setup", 
            "text": "You planet account comes with a brand new CLI and it allows you to perfrom basic functions such as search for ID[s] and for images in a specific location, export all image footprint in your area of interest and so on. Installation is pretty simple  pip install planet  You installation steps from earlier means you have managed to not only create the Google Earth Engine account but also installed its client. Incase you have missed it go to their main reference page for installation of their python client. Since you can consume Earth Engine using both Javascript(in browser) and Python(locally).", 
            "title": "2) Planet and Google Earth Engine(GEE) Command Line Interface(CLI) Setup"
        }, 
        {
            "location": "/projects/housekeeping/#3-location-to-gee-datasets", 
            "text": "From  Guillermo E. Ponce-Campos's earlier presentation , you saw the application of some datasets within Google Earth Engine. If the data is maintained as open access then you can add any of the datasets by simply adding the following lines first  var   neon_srer_hs   =   ee . ImageCollection ( users/gponce/usda_ars/image_collections/neon_srer_2017_hs )  var   rgb10cm   =   ee . ImageCollection ( users/gponce/usda_ars/image_collections/neon_srer_2017_rgb )  var   ltar_sites   =   ee . FeatureCollection ( users/gponce/usda_ars/shapefiles/LTAR/ltar_boundaries )  //get size of collection  print ( neon_sres_hs . size ())   for those using python API you can still access a collection  import   ee  ee . Initialize ()  neon_sres_hs = ee . ImageCollection ( users/gponce/usda_ars/image_collections/neon_srer_2017_hs )  ##you can even check how many images does the collection have  print ( neon_sres_hs . size () . getInfo ())", 
            "title": "3) Location to GEE datasets"
        }, 
        {
            "location": "/projects/housekeeping/#4-adding-additional-images", 
            "text": "For a minute there imagine you want to work with more data apart from the few areas we talked about, the Education and Research account gives you 10,000 square kilometer and you can then upload it into GEE.  For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually.  The image name is automatically filled in with the filename that you select when uploading.   Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help such as using the Google Earth Engine CLI.  For now you can use the tool I made to  batch upload collections along with their metadata into Google Earth Engine . You can install this by simply typing  pip install ppipe  You can read about the tool, it's setup and it's operation at  this Planet Story  Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be  found here", 
            "title": "4) Adding additional Images"
        }, 
        {
            "location": "/projects/housekeeping/#5-additional-tools-and-toolboxes-for-local-analysis", 
            "text": "If you need to handle the data locally using Matlab, QGIS or ArcMap make sure you have these softwares installed. The images can then be downloaded and analyzed using multiple methods and toolsets. A lot of these softwares have additional capabilities to help you further use Planet data. You can find a better reference of external integration here   ENVI Integration  ESRI Integration  Cesium Integration  Boundless  PCI Geomatics", 
            "title": "5) Additional Tools and Toolboxes for Local Analysis"
        }, 
        {
            "location": "/projects/downloading-images/", 
            "text": "Downloading Images\n\n\nYou can download images from Planet using a couple of methods, including but not limited to Planet Explorer or using a client to make requests to the Data API and downloading imagery.\n\n\nPlanet Explorer\n\n\nPlanet Explorer is probably one of the most useful and beloved interface to interact with and download Planet Labs satellite imagery. Not only does it allow you to filter your images to specific sensors but it also allows you to filter by cloud cover among other things. A neat little trick in Planet Explorer is that once the images are filtered if you want to download multiple images at once in an order you can hold down the control key(if using a windows machine) and click on multiple sets of imagery adding them to the same order.\n\n\n\n\nSteps to get satellite imagery from Planet Explorer\n\n\nOnce the images have been ordered sit back and relax as the order notification that your delivery is ready to be picked up will be emailed to you.\n\n\nTo interact with the \nData API\n and batch download imagery there is \nhost of Planet Platform documentation\n that teach you how to do that step by step.\n\n\nBatch Download Images\n\n\nI have also created another stand alone tool apart from the \nppipe tool\n to just download imagery once you have selected area of interest and sensor type. This will work if you have the (Planet Python Client installed). Incase you missed this in housekeeping you can [read it again].\n\n\nIt is using the Saved search function to allow you to batch download. You can find the \ntool here\n\n\nThis tool is a quick addon to existing application of planet saved searches to download images. This prints all the saved searches that you might have saved using the CLI or using the explorer. In which case you are able to set the filters, choose item types and date ranges and aoi within the Planet Explorer GUI and then be able to use the saved search name to execute a batch download command. This combines activation and download and works only for a single item type that was set in the search. You can choose to provide a limit which limits the number of item-asset combinations to download or use without limit and all items and asset combinations in the aoi will be downloaded.\n\n\nUsing with limits\n\n\npython saved_search_download.py \nsearch_name\n \nanalytic\n \nC:\\planet_demo\n \n10\n\n\n\n\n\nWithout limits the setup becomes\n\n\npython saved_search_download.py \nsearch_name\n \nanalytic\n \nC:\\planet_demo", 
            "title": "Downloading Images"
        }, 
        {
            "location": "/projects/downloading-images/#downloading-images", 
            "text": "You can download images from Planet using a couple of methods, including but not limited to Planet Explorer or using a client to make requests to the Data API and downloading imagery.", 
            "title": "Downloading Images"
        }, 
        {
            "location": "/projects/downloading-images/#planet-explorer", 
            "text": "Planet Explorer is probably one of the most useful and beloved interface to interact with and download Planet Labs satellite imagery. Not only does it allow you to filter your images to specific sensors but it also allows you to filter by cloud cover among other things. A neat little trick in Planet Explorer is that once the images are filtered if you want to download multiple images at once in an order you can hold down the control key(if using a windows machine) and click on multiple sets of imagery adding them to the same order.   Steps to get satellite imagery from Planet Explorer  Once the images have been ordered sit back and relax as the order notification that your delivery is ready to be picked up will be emailed to you.  To interact with the  Data API  and batch download imagery there is  host of Planet Platform documentation  that teach you how to do that step by step.", 
            "title": "Planet Explorer"
        }, 
        {
            "location": "/projects/downloading-images/#batch-download-images", 
            "text": "I have also created another stand alone tool apart from the  ppipe tool  to just download imagery once you have selected area of interest and sensor type. This will work if you have the (Planet Python Client installed). Incase you missed this in housekeeping you can [read it again].  It is using the Saved search function to allow you to batch download. You can find the  tool here  This tool is a quick addon to existing application of planet saved searches to download images. This prints all the saved searches that you might have saved using the CLI or using the explorer. In which case you are able to set the filters, choose item types and date ranges and aoi within the Planet Explorer GUI and then be able to use the saved search name to execute a batch download command. This combines activation and download and works only for a single item type that was set in the search. You can choose to provide a limit which limits the number of item-asset combinations to download or use without limit and all items and asset combinations in the aoi will be downloaded.  Using with limits  python saved_search_download.py  search_name   analytic   C:\\planet_demo   10   Without limits the setup becomes  python saved_search_download.py  search_name   analytic   C:\\planet_demo", 
            "title": "Batch Download Images"
        }, 
        {
            "location": "/projects/getting-images-ee/", 
            "text": "Getting Images into Google Earth Engine\n\n\nFor the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually.\n\n\nThe image name is automatically filled in with the filename that you select when uploading.\n\n\n\n\nNote you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help.\n\n\nFor now you can use the tool I made to batch upload collections along with their metadata into Google Earth Engine. You can read about the tool, it's setup and it's operation at \nthis Planet Story\n\n\nIncase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be \nfound here", 
            "title": "Getting Images into Google Earth Engine"
        }, 
        {
            "location": "/projects/getting-images-ee/#getting-images-into-google-earth-engine", 
            "text": "For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually.  The image name is automatically filled in with the filename that you select when uploading.   Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help.  For now you can use the tool I made to batch upload collections along with their metadata into Google Earth Engine. You can read about the tool, it's setup and it's operation at  this Planet Story  Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be  found here", 
            "title": "Getting Images into Google Earth Engine"
        }, 
        {
            "location": "/projects/functions/", 
            "text": "Functions in Earth Engine\n\n\nWhile single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics.\n\n\nFor this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed\n\n\n//Add an image collection\n\n\nvar\n \ncollection\n=\nee\n.\nImageCollection\n(\nLANDSAT/LT05/C01/T1_SR\n)\n\n\n\n//Filtering an Image Collection\n\n\nvar\n \nfiltered\n=\ncollection\n.\nfilterMetadata\n(\nWRS_PATH\n,\nequals\n,\n25\n)\n\n\n.\nfilterMetadata\n(\nWRS_ROW\n,\nequals\n,\n39\n).\nfilterMetadata\n(\nCLOUD_COVER\n,\nless_than\n,\n5\n)\n\n\n\n//print filtered collection properties\n\n\nprint\n(\nFiltered Collection\n,\nfiltered\n)\n\n\n\n\n/*=====================================================================================*/\n\n\n//Writing a function\n\n\nvar\n \naddNDVI\n \n=\n \nfunction\n(\nimage\n)\n \n{\n\n  \nvar\n \nndvi\n \n=\n \nimage\n.\nnormalizedDifference\n([\nB4\n,\n \nB3\n]).\nrename\n(\nNDVI\n);\n\n  \nreturn\n \nndvi\n;\n\n\n};\n\n\n\nvar\n \nndvicoll\n=\nfiltered\n.\nmap\n(\naddNDVI\n)\n\n\nprint\n(\nNDVI Collection\n,\nndvicoll\n)\n\n\n\n//Let\ns add a palette for us to show the results\n\n\nvar\n \nndvivis\n \n=\n \n{\nopacity\n:\n1\n,\nbands\n:\n[\nNDVI\n],\nmin\n:-\n0.5182320475578308\n,\nmax\n:\n0.7803871631622314\n,\npalette\n:\n[\nd49e8a\n,\nffcfb4\n,\necffcf\n,\n94ff8d\n,\n3eff56\n,\n15cc23\n]};\n\n\n\n//Add the first of the result\n\n\nMap\n.\naddLayer\n(\nee\n.\nImage\n(\nndvicoll\n.\nfirst\n()),\nndvivis\n,\nNDVI\n)", 
            "title": "Functions"
        }, 
        {
            "location": "/projects/functions/#functions-in-earth-engine", 
            "text": "While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics.  For this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed  //Add an image collection  var   collection = ee . ImageCollection ( LANDSAT/LT05/C01/T1_SR )  //Filtering an Image Collection  var   filtered = collection . filterMetadata ( WRS_PATH , equals , 25 )  . filterMetadata ( WRS_ROW , equals , 39 ). filterMetadata ( CLOUD_COVER , less_than , 5 )  //print filtered collection properties  print ( Filtered Collection , filtered )  /*=====================================================================================*/  //Writing a function  var   addNDVI   =   function ( image )   { \n   var   ndvi   =   image . normalizedDifference ([ B4 ,   B3 ]). rename ( NDVI ); \n   return   ndvi ;  };  var   ndvicoll = filtered . map ( addNDVI )  print ( NDVI Collection , ndvicoll )  //Let s add a palette for us to show the results  var   ndvivis   =   { opacity : 1 , bands : [ NDVI ], min :- 0.5182320475578308 , max : 0.7803871631622314 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]};  //Add the first of the result  Map . addLayer ( ee . Image ( ndvicoll . first ()), ndvivis , NDVI )", 
            "title": "Functions in Earth Engine"
        }, 
        {
            "location": "/projects/reducers/", 
            "text": "Reducers \n Charts in Earth Engine\n\n\nWhile single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics.\n\n\n\n\nSource: \nImage Collection Reductions from Google Earth Engine\n\n\nFor this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed. Now the additional step we added here was running the produced collection through a median reducer. We can then print the median values. The last step we create a setup for the chart and the plot the chart of the median\n\n\n/*Add some field points and name the geometry\n\n\nas field this script won\nt work till then*/\n\n\n\n//Add an image collection\n\n\nvar\n \ncollection\n=\nee\n.\nImageCollection\n(\nLANDSAT/LT05/C01/T1_SR\n)\n\n\n\n//Filtering an Image Collection\n\n\nvar\n \nfiltered\n=\ncollection\n.\nfilterMetadata\n(\nWRS_PATH\n,\nequals\n,\n25\n)\n\n\n.\nfilterMetadata\n(\nWRS_ROW\n,\nequals\n,\n39\n).\nfilterMetadata\n(\nCLOUD_COVER\n,\nless_than\n,\n5\n)\n\n\n\n//print filtered collection properties\n\n\nprint\n(\nFiltered Collection\n,\nfiltered\n)\n\n\n\n\n/*==================================================*/\n\n\n//Writing a function\n\n\nvar\n \naddNDVI\n \n=\n \nfunction\n(\nimage\n)\n \n{\n\n  \nvar\n \nndvi\n \n=\n \nimage\n.\nnormalizedDifference\n([\nB4\n,\n \nB3\n]).\nrename\n(\nNDVI\n);\n\n  \nreturn\n \nndvi\n;\n\n\n};\n\n\n\nvar\n \nndvicoll\n=\nfiltered\n.\nmap\n(\naddNDVI\n)\n\n\nprint\n(\nNDVI Collection\n,\nndvicoll\n)\n\n\n\n//Let\ns add a palette for us to show the results\n\n\nvar\n \nndvivis\n \n=\n \n{\nopacity\n:\n1\n,\nbands\n:\n[\nNDVI\n],\nmin\n:-\n0.5182320475578308\n,\nmax\n:\n0.7803871631622314\n,\npalette\n:\n[\nd49e8a\n,\nffcfb4\n,\necffcf\n,\n94ff8d\n,\n3eff56\n,\n15cc23\n]};\n\n\n\n//Add the first of the result\n\n\nMap\n.\naddLayer\n(\nee\n.\nImage\n(\nndvicoll\n.\nfirst\n()),\nndvivis\n,\nNDVI\n)\n\n\n\n//Add an reducer\n\n\nvar\n \nndviav\n=\nndvicoll\n.\nreduce\n(\nee\n.\nReducer\n.\nmedian\n());\n\n\n\nMap\n.\naddLayer\n(\nndviav\n.\nselect\n(\nNDVI_median\n).\nrename\n(\nNDVI\n),\nndvivis\n,\nNDVI Median\n)\n\n\nprint\n(\nndviav\n)\n\n\n\n\n\n\n\n\nTop: Field points to look at median NDVI, Bottom: Chart generated from field point\n\n\nvar\n \nndvionly\n=\nndviav\n.\nselect\n(\nNDVI_median\n).\nrename\n(\nNDVI\n)\n\n\n\nvar\n \nchart\n \n=\n \nui\n.\nChart\n.\nimage\n.\nbyRegion\n({\n\n  \nimage\n:\n \nndvionly\n,\n\n  \nregions\n:\n \nfield\n,\n\n  \nscale\n:\n \n30\n\n\n});\n\n\nchart\n.\nsetOptions\n({\n\n  \ntitle\n:\n \nCharting NDVI\n,\n\n  \nvAxis\n:\n \n{\n\n    \ntitle\n:\n \nNDVI\n\n  \n},\n\n  \nlegend\n:\n \nnone\n,\n\n  \nlineWidth\n:\n \n1\n,\n\n  \npointSize\n:\n \n4\n\n\n});\n\n\n\nprint\n(\nchart\n);", 
            "title": "Reducers and Charts"
        }, 
        {
            "location": "/projects/reducers/#reducers-charts-in-earth-engine", 
            "text": "While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics.   Source:  Image Collection Reductions from Google Earth Engine  For this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed. Now the additional step we added here was running the produced collection through a median reducer. We can then print the median values. The last step we create a setup for the chart and the plot the chart of the median  /*Add some field points and name the geometry  as field this script won t work till then*/  //Add an image collection  var   collection = ee . ImageCollection ( LANDSAT/LT05/C01/T1_SR )  //Filtering an Image Collection  var   filtered = collection . filterMetadata ( WRS_PATH , equals , 25 )  . filterMetadata ( WRS_ROW , equals , 39 ). filterMetadata ( CLOUD_COVER , less_than , 5 )  //print filtered collection properties  print ( Filtered Collection , filtered )  /*==================================================*/  //Writing a function  var   addNDVI   =   function ( image )   { \n   var   ndvi   =   image . normalizedDifference ([ B4 ,   B3 ]). rename ( NDVI ); \n   return   ndvi ;  };  var   ndvicoll = filtered . map ( addNDVI )  print ( NDVI Collection , ndvicoll )  //Let s add a palette for us to show the results  var   ndvivis   =   { opacity : 1 , bands : [ NDVI ], min :- 0.5182320475578308 , max : 0.7803871631622314 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]};  //Add the first of the result  Map . addLayer ( ee . Image ( ndvicoll . first ()), ndvivis , NDVI )  //Add an reducer  var   ndviav = ndvicoll . reduce ( ee . Reducer . median ());  Map . addLayer ( ndviav . select ( NDVI_median ). rename ( NDVI ), ndvivis , NDVI Median )  print ( ndviav )     Top: Field points to look at median NDVI, Bottom: Chart generated from field point  var   ndvionly = ndviav . select ( NDVI_median ). rename ( NDVI )  var   chart   =   ui . Chart . image . byRegion ({ \n   image :   ndvionly , \n   regions :   field , \n   scale :   30  });  chart . setOptions ({ \n   title :   Charting NDVI , \n   vAxis :   { \n     title :   NDVI \n   }, \n   legend :   none , \n   lineWidth :   1 , \n   pointSize :   4  });  print ( chart );", 
            "title": "Reducers &amp; Charts in Earth Engine"
        }, 
        {
            "location": "/projects/multiyear/", 
            "text": "Multiyear Cloud Free Composites in Earth Engine\n\n\nOne of the most sought after functions in Earth Engine is the possibility of using deep time stack imagery to create cloud free composites. One of the simplest way of thinking about this is to use reducers that we talked about earlier, where we look at an entire stack of pixels and choose the median value of the distribution of pixel across stack and we end up getting a cloud free composite over the given time period. Depending on the number of images, the actual number of cloud free images in the overall stack your results may need more fine tune adjustments.\n\n\n\n\nMulti Year Composite: A single year is added FCC\n\n\nFor this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate yearly composites from 1984 to 2010 using the Landsat 5 data. Note that this is another way of creating a function where we have inserted the map function and the collection inside the function so it can be run directly. We might be interested in sorting these collections using year and hence we set the year as a metadata for each image in the cloud free composite. Depending on the type of imagery another good way of creating cloud free composites is by using the pixel qa bit bands in the Landsat surface reflectance imagery.\n\n\n//Add an image collection\n\n\nvar\n \ncollection\n=\nee\n.\nImageCollection\n(\nLANDSAT/LT05/C01/T1_SR\n)\n\n\n\n//Filtering an Image Collection\n\n\nvar\n \nfiltered\n=\ncollection\n.\nfilterMetadata\n(\nWRS_PATH\n,\nequals\n,\n25\n)\n\n\n.\nfilterMetadata\n(\nWRS_ROW\n,\nequals\n,\n39\n).\nfilterMetadata\n(\nCLOUD_COVER\n,\nless_than\n,\n15\n)\n\n\n\n//print filtered collection properties\n\n\nprint\n(\nFiltered Collection\n,\nfiltered\n)\n\n\n\n//Create Multi Year Composite from Landsat 5 Surface Reflectance\n\n\nvar\n \nyears\n \n=\n \nee\n.\nList\n.\nsequence\n(\n1984\n,\n \n2010\n)\n\n\n\nvar\n \nmultiyear\n \n=\n \nee\n.\nImageCollection\n(\nyears\n\n  \n.\nmap\n(\nfunction\n(\ny\n)\n \n{\n\n    \nvar\n \nstart\n \n=\n \nee\n.\nDate\n.\nfromYMD\n(\ny\n,\n \n1\n,\n \n1\n)\n\n    \nvar\n \nend\n \n=\n \nstart\n.\nadvance\n(\n1\n,\n \nyear\n);\n\n    \nvar\n \nimage\n \n=\n \nfiltered\n.\nfilterDate\n(\nstart\n,\n \nend\n).\nmedian\n();\n\n    \nreturn\n \nimage\n.\nset\n(\nyear\n,\n \ny\n)\n\n\n}))\n\n\n\nprint\n(\nmultiyear\n);\n\n\n\n//Add a visualization\n\n\nvar\n \nvis\n \n=\n \n{\nopacity\n:\n1\n,\nbands\n:\n[\nB4\n,\nB3\n,\nB2\n],\nmin\n:-\n95.56918120427508\n,\nmax\n:\n2171.008347369839\n,\ngamma\n:\n1\n};\n\n\n\n//Add the Image\n\n\nMap\n.\naddLayer\n(\nee\n.\nImage\n(\nee\n.\nImageCollection\n(\nmultiyear\n).\nfirst\n()),\nvis\n,\nMedian from MultiYear\n)", 
            "title": "Multiyear Cloud free composites"
        }, 
        {
            "location": "/projects/multiyear/#multiyear-cloud-free-composites-in-earth-engine", 
            "text": "One of the most sought after functions in Earth Engine is the possibility of using deep time stack imagery to create cloud free composites. One of the simplest way of thinking about this is to use reducers that we talked about earlier, where we look at an entire stack of pixels and choose the median value of the distribution of pixel across stack and we end up getting a cloud free composite over the given time period. Depending on the number of images, the actual number of cloud free images in the overall stack your results may need more fine tune adjustments.   Multi Year Composite: A single year is added FCC  For this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate yearly composites from 1984 to 2010 using the Landsat 5 data. Note that this is another way of creating a function where we have inserted the map function and the collection inside the function so it can be run directly. We might be interested in sorting these collections using year and hence we set the year as a metadata for each image in the cloud free composite. Depending on the type of imagery another good way of creating cloud free composites is by using the pixel qa bit bands in the Landsat surface reflectance imagery.  //Add an image collection  var   collection = ee . ImageCollection ( LANDSAT/LT05/C01/T1_SR )  //Filtering an Image Collection  var   filtered = collection . filterMetadata ( WRS_PATH , equals , 25 )  . filterMetadata ( WRS_ROW , equals , 39 ). filterMetadata ( CLOUD_COVER , less_than , 15 )  //print filtered collection properties  print ( Filtered Collection , filtered )  //Create Multi Year Composite from Landsat 5 Surface Reflectance  var   years   =   ee . List . sequence ( 1984 ,   2010 )  var   multiyear   =   ee . ImageCollection ( years \n   . map ( function ( y )   { \n     var   start   =   ee . Date . fromYMD ( y ,   1 ,   1 ) \n     var   end   =   start . advance ( 1 ,   year ); \n     var   image   =   filtered . filterDate ( start ,   end ). median (); \n     return   image . set ( year ,   y )  }))  print ( multiyear );  //Add a visualization  var   vis   =   { opacity : 1 , bands : [ B4 , B3 , B2 ], min :- 95.56918120427508 , max : 2171.008347369839 , gamma : 1 };  //Add the Image  Map . addLayer ( ee . Image ( ee . ImageCollection ( multiyear ). first ()), vis , Median from MultiYear )", 
            "title": "Multiyear Cloud Free Composites in Earth Engine"
        }, 
        {
            "location": "/projects/export/", 
            "text": "Export Images in Earth Engine\n\n\nWhen we are all said and done we still want to export the images. Google Earth Engine allows you to export images externally into two subsystems, a Google Cloud Storage Bucket(Free quota upto 5 GB) or Google Drive (This is tied to your overall quota). The method we are exploring right now is export to Google Drive, and then being able to import the analyzed image into any local tool or libraries. It is possible to export entire collections to drive using batch exports in the python API client. This avoids the need for you to click on the Run button everytime an export task has to be started.\n\n\n\n\nExport Window: Export Image to Google Drive\n\n\nFor this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate yearly composites from 1984 to 2010 using the Landsat 5 data. Note that this is another way of creating a function where we have inserted the map function and the collection inside the function so it can be run directly. We might be interested in sorting these collections using year and hence we set the year as a metadata for each image in the cloud free composite. Depending on the type of imagery another good way of creating cloud free composites is by using the pixel qa bit bands in the Landsat surface reflectance imagery. The last step that is added is the Export to drive function, where we set up the image name, the image type, the scale and the region refers to areas over which we are exporting this imagery.\n\n\n//Add an image collection\n\n\nvar\n \ncollection\n=\nee\n.\nImageCollection\n(\nLANDSAT/LT05/C01/T1_SR\n)\n\n\n\n//Filtering an Image Collection\n\n\nvar\n \nfiltered\n=\ncollection\n.\nfilterMetadata\n(\nWRS_PATH\n,\nequals\n,\n25\n)\n\n\n.\nfilterMetadata\n(\nWRS_ROW\n,\nequals\n,\n39\n).\nfilterMetadata\n(\nCLOUD_COVER\n,\nless_than\n,\n15\n)\n\n\n\n//print filtered collection properties\n\n\nprint\n(\nFiltered Collection\n,\nfiltered\n)\n\n\n\n//Create Multi Year Composite from Landsat 5 Surface Reflectance\n\n\nvar\n \nyears\n \n=\n \nee\n.\nList\n.\nsequence\n(\n1984\n,\n \n2010\n)\n\n\n\nvar\n \nmultiyear\n \n=\n \nee\n.\nImageCollection\n(\nyears\n\n  \n.\nmap\n(\nfunction\n(\ny\n)\n \n{\n\n    \nvar\n \nstart\n \n=\n \nee\n.\nDate\n.\nfromYMD\n(\ny\n,\n \n1\n,\n \n1\n)\n\n    \nvar\n \nend\n \n=\n \nstart\n.\nadvance\n(\n1\n,\n \nyear\n);\n\n    \nvar\n \nimage\n \n=\n \nfiltered\n.\nfilterDate\n(\nstart\n,\n \nend\n).\nmedian\n();\n\n    \nreturn\n \nimage\n.\nset\n(\nyear\n,\n \ny\n)\n\n\n}))\n\n\n\nprint\n(\nmultiyear\n);\n\n\n\n//Add a visualization\n\n\nvar\n \nvis\n \n=\n \n{\nopacity\n:\n1\n,\nbands\n:\n[\nB4\n,\nB3\n,\nB2\n],\nmin\n:-\n95.56918120427508\n,\nmax\n:\n2171.008347369839\n,\ngamma\n:\n1\n};\n\n\n\n//Add the Image\n\n\nMap\n.\naddLayer\n(\nee\n.\nImage\n(\nee\n.\nImageCollection\n(\nmultiyear\n).\nfirst\n()),\nvis\n,\nMedian from MultiYear\n)\n\n\n\n//Export Imagery\n\n\nExport\n.\nimage\n.\ntoDrive\n({\n\n  \nimage\n:\nee\n.\nImage\n(\nee\n.\nImageCollection\n(\nmultiyear\n).\nfirst\n())\n\n  \n.\nselect\n([\nB1\n,\nB2\n,\nB3\n,\nB4\n,\nB5\n,\nB6\n,\nB7\n]).\ntoUint16\n(),\n\n  \ndescription\n:\n \nMedian-Image-Export\n,\n\n  \nfolder\n:\n \nEE-CSDMS-Test\n,\n\n  \nscale\n:\n30\n,\n\n  \nregion\n:\n \ngeometry\n,\n\n  \nmaxPixels\n:\n10\ne12\n\n\n})\n\n\n\n\n\nExporting video seems like the obvious thing to do after this. For this a couple of things to keep in mind, you can only export 3 band videos cast to a 8 bit image per frame. You can sort these images before export and that is the ordering of the frames.\n\n\n// Load and format the collection to export.\n\n\nvar\n \nframe\n \n=\n \nee\n.\nImageCollection\n(\nmultiyear\n)\n\n  \n.\nsort\n(\nyear\n)\n\n  \n.\nselect\n([\nB4\n,\n \nB3\n,\n \nB2\n])\n\n  \n.\nmap\n(\nfunction\n(\nimage\n)\n \n{\n\n    \nreturn\n \nimage\n.\nvisualize\n({\nbands\n:\n \n[\nB4\n,\n \nB3\n,\n \nB2\n],\n \nmin\n:\n \n-\n100\n,\n \nmax\n:\n2200\n})\n\n    \n.\nset\n(\nyear\n,\nimage\n.\nget\n(\nyear\n));\n\n  \n});\n\n\n\n// Export video\n\n\nExport\n.\nvideo\n.\ntoDrive\n({\n\n  \ncollection\n:\n \nframe\n,\n\n  \nfolder\n:\n \nEE-CSDMS-Test\n,\n\n  \ndescription\n:\n \nEE-CSDMS-Video\n,\n\n  \ndimensions\n:\n \n1080\n,\n\n  \nframesPerSecond\n:\n \n1\n,\n\n  \nregion\n:\n \ngeometry\n\n\n});", 
            "title": "Earth Engine exports"
        }, 
        {
            "location": "/projects/export/#export-images-in-earth-engine", 
            "text": "When we are all said and done we still want to export the images. Google Earth Engine allows you to export images externally into two subsystems, a Google Cloud Storage Bucket(Free quota upto 5 GB) or Google Drive (This is tied to your overall quota). The method we are exploring right now is export to Google Drive, and then being able to import the analyzed image into any local tool or libraries. It is possible to export entire collections to drive using batch exports in the python API client. This avoids the need for you to click on the Run button everytime an export task has to be started.   Export Window: Export Image to Google Drive  For this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate yearly composites from 1984 to 2010 using the Landsat 5 data. Note that this is another way of creating a function where we have inserted the map function and the collection inside the function so it can be run directly. We might be interested in sorting these collections using year and hence we set the year as a metadata for each image in the cloud free composite. Depending on the type of imagery another good way of creating cloud free composites is by using the pixel qa bit bands in the Landsat surface reflectance imagery. The last step that is added is the Export to drive function, where we set up the image name, the image type, the scale and the region refers to areas over which we are exporting this imagery.  //Add an image collection  var   collection = ee . ImageCollection ( LANDSAT/LT05/C01/T1_SR )  //Filtering an Image Collection  var   filtered = collection . filterMetadata ( WRS_PATH , equals , 25 )  . filterMetadata ( WRS_ROW , equals , 39 ). filterMetadata ( CLOUD_COVER , less_than , 15 )  //print filtered collection properties  print ( Filtered Collection , filtered )  //Create Multi Year Composite from Landsat 5 Surface Reflectance  var   years   =   ee . List . sequence ( 1984 ,   2010 )  var   multiyear   =   ee . ImageCollection ( years \n   . map ( function ( y )   { \n     var   start   =   ee . Date . fromYMD ( y ,   1 ,   1 ) \n     var   end   =   start . advance ( 1 ,   year ); \n     var   image   =   filtered . filterDate ( start ,   end ). median (); \n     return   image . set ( year ,   y )  }))  print ( multiyear );  //Add a visualization  var   vis   =   { opacity : 1 , bands : [ B4 , B3 , B2 ], min :- 95.56918120427508 , max : 2171.008347369839 , gamma : 1 };  //Add the Image  Map . addLayer ( ee . Image ( ee . ImageCollection ( multiyear ). first ()), vis , Median from MultiYear )  //Export Imagery  Export . image . toDrive ({ \n   image : ee . Image ( ee . ImageCollection ( multiyear ). first ()) \n   . select ([ B1 , B2 , B3 , B4 , B5 , B6 , B7 ]). toUint16 (), \n   description :   Median-Image-Export , \n   folder :   EE-CSDMS-Test , \n   scale : 30 , \n   region :   geometry , \n   maxPixels : 10 e12  })   Exporting video seems like the obvious thing to do after this. For this a couple of things to keep in mind, you can only export 3 band videos cast to a 8 bit image per frame. You can sort these images before export and that is the ordering of the frames.  // Load and format the collection to export.  var   frame   =   ee . ImageCollection ( multiyear ) \n   . sort ( year ) \n   . select ([ B4 ,   B3 ,   B2 ]) \n   . map ( function ( image )   { \n     return   image . visualize ({ bands :   [ B4 ,   B3 ,   B2 ],   min :   - 100 ,   max : 2200 }) \n     . set ( year , image . get ( year )); \n   });  // Export video  Export . video . toDrive ({ \n   collection :   frame , \n   folder :   EE-CSDMS-Test , \n   description :   EE-CSDMS-Video , \n   dimensions :   1080 , \n   framesPerSecond :   1 , \n   region :   geometry  });", 
            "title": "Export Images in Earth Engine"
        }, 
        {
            "location": "/projects/functions/", 
            "text": "Functions in Earth Engine\n\n\nWhile single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics.\n\n\nFor this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed\n\n\n//Add an image collection\n\n\nvar\n \ncollection\n=\nee\n.\nImageCollection\n(\nLANDSAT/LT05/C01/T1_SR\n)\n\n\n\n//Filtering an Image Collection\n\n\nvar\n \nfiltered\n=\ncollection\n.\nfilterMetadata\n(\nWRS_PATH\n,\nequals\n,\n25\n)\n\n\n.\nfilterMetadata\n(\nWRS_ROW\n,\nequals\n,\n39\n).\nfilterMetadata\n(\nCLOUD_COVER\n,\nless_than\n,\n5\n)\n\n\n\n//print filtered collection properties\n\n\nprint\n(\nFiltered Collection\n,\nfiltered\n)\n\n\n\n\n/*=====================================================================================*/\n\n\n//Writing a function\n\n\nvar\n \naddNDVI\n \n=\n \nfunction\n(\nimage\n)\n \n{\n\n  \nvar\n \nndvi\n \n=\n \nimage\n.\nnormalizedDifference\n([\nB4\n,\n \nB3\n]).\nrename\n(\nNDVI\n);\n\n  \nreturn\n \nndvi\n;\n\n\n};\n\n\n\nvar\n \nndvicoll\n=\nfiltered\n.\nmap\n(\naddNDVI\n)\n\n\nprint\n(\nNDVI Collection\n,\nndvicoll\n)\n\n\n\n//Let\ns add a palette for us to show the results\n\n\nvar\n \nndvivis\n \n=\n \n{\nopacity\n:\n1\n,\nbands\n:\n[\nNDVI\n],\nmin\n:-\n0.5182320475578308\n,\nmax\n:\n0.7803871631622314\n,\npalette\n:\n[\nd49e8a\n,\nffcfb4\n,\necffcf\n,\n94ff8d\n,\n3eff56\n,\n15cc23\n]};\n\n\n\n//Add the first of the result\n\n\nMap\n.\naddLayer\n(\nee\n.\nImage\n(\nndvicoll\n.\nfirst\n()),\nndvivis\n,\nNDVI\n)", 
            "title": "Collection NDVI"
        }, 
        {
            "location": "/projects/functions/#functions-in-earth-engine", 
            "text": "While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics.  For this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed  //Add an image collection  var   collection = ee . ImageCollection ( LANDSAT/LT05/C01/T1_SR )  //Filtering an Image Collection  var   filtered = collection . filterMetadata ( WRS_PATH , equals , 25 )  . filterMetadata ( WRS_ROW , equals , 39 ). filterMetadata ( CLOUD_COVER , less_than , 5 )  //print filtered collection properties  print ( Filtered Collection , filtered )  /*=====================================================================================*/  //Writing a function  var   addNDVI   =   function ( image )   { \n   var   ndvi   =   image . normalizedDifference ([ B4 ,   B3 ]). rename ( NDVI ); \n   return   ndvi ;  };  var   ndvicoll = filtered . map ( addNDVI )  print ( NDVI Collection , ndvicoll )  //Let s add a palette for us to show the results  var   ndvivis   =   { opacity : 1 , bands : [ NDVI ], min :- 0.5182320475578308 , max : 0.7803871631622314 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]};  //Add the first of the result  Map . addLayer ( ee . Image ( ndvicoll . first ()), ndvivis , NDVI )", 
            "title": "Functions in Earth Engine"
        }, 
        {
            "location": "/projects/edges/", 
            "text": "Edge Detection\n\n\nYou can also run powerful functions such as edge detection using Hough and Canny transforms for example for single images as well as on collections to do edge counts, connectivity measures among a few other applications.\n\n\n\n\nSimilar to earlier example you can access the \nfull script here\n or copy and past the same code into \ncode.earthengine.google.com\n\n\nvar\n \nimage\n \n=\n \nee\n.\nImage\n(\nusers/samapriya/planet-impact/neon_ps4b_sr/20170415_171504_1005_3B_AnalyticMS_SR\n)\n\n\nvar\n \nimagevis\n \n=\n \n{\nopacity\n:\n1\n,\nbands\n:\n[\nb4\n,\nb3\n,\nb2\n],\nmin\n:\n671\n,\nmax\n:\n4666\n,\ngamma\n:\n1\n}\n\n\n\nvar\n \nndvi\n \n=\n \nimage\n.\nnormalizedDifference\n([\nb4\n,\n \nb3\n]);\n\n\n\n// Apply a Canny edge detector.\n\n\nvar\n \ncanny\n \n=\n \nee\n.\nAlgorithms\n.\nCannyEdgeDetector\n({\n\n  \nimage\n:\n \nndvi\n,\n\n  \nthreshold\n:\n \n0.3\n\n\n}).\nmultiply\n(\n255\n);\n\n\n\n// Apply the Hough transform.\n\n\nvar\n \nh\n \n=\n \nee\n.\nAlgorithms\n.\nHoughTransform\n({\n\n  \nimage\n:\n \ncanny\n,\n\n  \ngridSize\n:\n \n256\n,\n\n  \ninputThreshold\n:\n \n100\n,\n\n  \nlineThreshold\n:\n \n100\n\n\n});\n\n\n\n// Display.\n\n\nMap\n.\nsetCenter\n(\n-\n110.9959\n,\n \n31.8385\n,\n13\n);\n\n\nMap\n.\naddLayer\n(\nimage\n,\n \nimagevis\n,\n \nsource_image\n);\n\n\nMap\n.\naddLayer\n(\nndvi\n,{\nmin\n:\n \n-\n0.05\n,\n \nmax\n:\n \n0.5\n},\n \nNDVI\n,\nfalse\n)\n\n\nMap\n.\naddLayer\n(\ncanny\n.\nupdateMask\n(\ncanny\n),\n \n{\nmin\n:\n \n0\n,\n \nmax\n:\n \n1\n,\n \npalette\n:\n \nblue\n},\n \ncanny\n);\n\n\nMap\n.\naddLayer\n(\nh\n.\nupdateMask\n(\nh\n),\n \n{\nmin\n:\n \n0\n,\n \nmax\n:\n \n1\n,\n \npalette\n:\n \nred\n},\n \nhough\n);\n\n\nMap\n.\nsetOptions\n(\nSATELLITE\n)", 
            "title": "Edge Detection"
        }, 
        {
            "location": "/projects/edges/#edge-detection", 
            "text": "You can also run powerful functions such as edge detection using Hough and Canny transforms for example for single images as well as on collections to do edge counts, connectivity measures among a few other applications.   Similar to earlier example you can access the  full script here  or copy and past the same code into  code.earthengine.google.com  var   image   =   ee . Image ( users/samapriya/planet-impact/neon_ps4b_sr/20170415_171504_1005_3B_AnalyticMS_SR )  var   imagevis   =   { opacity : 1 , bands : [ b4 , b3 , b2 ], min : 671 , max : 4666 , gamma : 1 }  var   ndvi   =   image . normalizedDifference ([ b4 ,   b3 ]);  // Apply a Canny edge detector.  var   canny   =   ee . Algorithms . CannyEdgeDetector ({ \n   image :   ndvi , \n   threshold :   0.3  }). multiply ( 255 );  // Apply the Hough transform.  var   h   =   ee . Algorithms . HoughTransform ({ \n   image :   canny , \n   gridSize :   256 , \n   inputThreshold :   100 , \n   lineThreshold :   100  });  // Display.  Map . setCenter ( - 110.9959 ,   31.8385 , 13 );  Map . addLayer ( image ,   imagevis ,   source_image );  Map . addLayer ( ndvi ,{ min :   - 0.05 ,   max :   0.5 },   NDVI , false )  Map . addLayer ( canny . updateMask ( canny ),   { min :   0 ,   max :   1 ,   palette :   blue },   canny );  Map . addLayer ( h . updateMask ( h ),   { min :   0 ,   max :   1 ,   palette :   red },   hough );  Map . setOptions ( SATELLITE )", 
            "title": "Edge Detection"
        }, 
        {
            "location": "/citations/", 
            "text": "Citations\n\n\nCiting Planet Data\n\n\nFrom a concept in our garage, to operating the largest fleet of Earth-imaging satellites, many people have invested time and energy in developing and enabling access to Planet\u2019s unique data feed. Please cite Planet when using our imagery and tools.\n\n\nTo cite Planet data in publications, please use the following:\n\n\nPlanet Team (2017). Planet Application Program Interface: In Space for Life on Earth. San Francisco, CA. \nhttps://api.planet.com\n.\n\n\nCiting Tools\n\n\nIf you use my tool and find it useful, you can cite that too\n\n\nPlanet-GEE-Pipeline-CLI\n\n\n\n\n\n\nSamapriya Roy. (2018, August 8). samapriya/Planet-GEE-Pipeline-CLI: Planet-GEE-Pipeline-CLI (Version 0.3.9).\nZenodo. http://doi.org/10.5281/zenodo.1341565\n\n\n\n\nGEE Asset Manager Addons\n\n\n\n\n\n\nSamapriya Roy. (2017, November 29). samapriya/gee_asset_manager_addon: GEE Asset Manager with Addons (Version 0.2.2).\nZenodo. http://doi.org/10.5281/zenodo.1068184", 
            "title": "Citations"
        }, 
        {
            "location": "/citations/#citations", 
            "text": "", 
            "title": "Citations"
        }, 
        {
            "location": "/citations/#citing-planet-data", 
            "text": "From a concept in our garage, to operating the largest fleet of Earth-imaging satellites, many people have invested time and energy in developing and enabling access to Planet\u2019s unique data feed. Please cite Planet when using our imagery and tools.  To cite Planet data in publications, please use the following:  Planet Team (2017). Planet Application Program Interface: In Space for Life on Earth. San Francisco, CA.  https://api.planet.com .", 
            "title": "Citing Planet Data"
        }, 
        {
            "location": "/citations/#citing-tools", 
            "text": "If you use my tool and find it useful, you can cite that too  Planet-GEE-Pipeline-CLI    Samapriya Roy. (2018, August 8). samapriya/Planet-GEE-Pipeline-CLI: Planet-GEE-Pipeline-CLI (Version 0.3.9).\nZenodo. http://doi.org/10.5281/zenodo.1341565  GEE Asset Manager Addons    Samapriya Roy. (2017, November 29). samapriya/gee_asset_manager_addon: GEE Asset Manager with Addons (Version 0.2.2).\nZenodo. http://doi.org/10.5281/zenodo.1068184", 
            "title": "Citing Tools"
        }, 
        {
            "location": "/contact/", 
            "text": "Contact Us\n\n\n\n\nDirector of Academic Programs at Planet\n\nEmail: joe.mascaro@planet.com\n\n\n\n\n\n\nPhD Candidate \n Intern Senior Developer Advocate at Planet\nDepartment of Geography\nIndiana University\nBloomington, Indiana\n\nEmail:\nsamapriya.roy@gmail.com\n\nGithub:\nsamapriya.github.io", 
            "title": "Contact Us"
        }, 
        {
            "location": "/contact/#contact-us", 
            "text": "Director of Academic Programs at Planet\n\nEmail: joe.mascaro@planet.com   PhD Candidate   Intern Senior Developer Advocate at Planet\nDepartment of Geography\nIndiana University\nBloomington, Indiana\n\nEmail:\nsamapriya.roy@gmail.com\n\nGithub:\nsamapriya.github.io", 
            "title": "Contact Us"
        }
    ]
}